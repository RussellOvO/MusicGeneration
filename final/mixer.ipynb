{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1v2Jl_FCXpy"
      },
      "source": [
        "# Mixer\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnueAlGvTPke"
      },
      "source": [
        "## Download and Import\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHAjFGH2bR7r"
      },
      "outputs": [],
      "source": [
        "!apt install fluidsynth\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2\n",
        "!pip install midi2audio\n",
        "!pip install music21\n",
        "\n",
        "from google.colab import files\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import glob\n",
        "from music21 import *\n",
        "from midi2audio import FluidSynth\n",
        "from IPython.display import Audio\n",
        "from keras.models import load_model\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLBMX09oTnmf"
      },
      "source": [
        "## Upload the Pre-trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T8wFmeRZX5s"
      },
      "outputs": [],
      "source": [
        "print(\"Please drag and drop Model.zip file in the Colab files folder\" +\n",
        "      \"\\nor select your model (Model.zip):\\n\")\n",
        "files_model = files.upload()\n",
        "\n",
        "zf = ZipFile(\"Model.zip\", 'r')\n",
        "zf.extractall('')\n",
        "zf.close()\n",
        "print(\"Finish!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY1yVf9GTylk"
      },
      "source": [
        "## Main Functions\n",
        "\n",
        "\n",
        "*   **parser:**  pre-process data\n",
        "\n",
        "*   **part_generate:** create music\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i-zzY63Azu_"
      },
      "outputs": [],
      "source": [
        "def parser():\n",
        "  \"\"\" Get all the rests and notes and chords from the midi files \"\"\"\n",
        "  transfer_dic = dict()\n",
        "  notes = []\n",
        "  for file in glob.glob(\"*.mid\"):\n",
        "      midi = converter.parse(file)\n",
        "      print(\"Parsing %s\" % file)\n",
        "      for element in midi.flat.elements:\n",
        "          if isinstance(element, note.Rest) and element.offset != 0:\n",
        "              notes.append('R')\n",
        "          if isinstance(element, note.Note):\n",
        "              notes.append(str(element.pitch))\n",
        "          if isinstance(element, chord.Chord):\n",
        "              notes.append('.'.join(str(pitch) for pitch in element.pitches))\n",
        "  note_set = sorted(set(note for note in notes))\n",
        "  # A dictionary to map notes, chords and rest to integers\n",
        "  transfer_dic = dict((note, number) for number, note in enumerate(note_set))\n",
        "  return transfer_dic\n",
        "\n",
        "\n",
        "def part_generate(instrument, note_interval, transfer_dic):\n",
        "  #load model\n",
        "  model = load_model(\"generator.h5\")\n",
        "\n",
        "  # Use random noise to generate sequences\n",
        "  noise = np.random.normal(0, 1, (1, 1000))\n",
        "  predictions = model.predict(noise)\n",
        "\n",
        "  # transfer sequence numbers to notes\n",
        "  boundary = int(len(transfer_dic) / 2)\n",
        "  pred_nums = [x * boundary + boundary for x in predictions[0]]\n",
        "  notes = [key for key in transfer_dic]\n",
        "  pred_notes = [notes[int(x)] for x in pred_nums]\n",
        "\n",
        "  offset = 0\n",
        "  p = stream.Part()\n",
        "  p.insert(instrument)\n",
        "  m1p = stream.Measure()\n",
        "  # create note and chord objects based on the values generated by the model\n",
        "  for pattern in pred_notes:\n",
        "      # rest\n",
        "      if pattern == 'R':\n",
        "          m1p.append(note.Rest())\n",
        "      # chord\n",
        "      elif ('.' in pattern) or pattern.isdigit():\n",
        "          notes_in_chord = pattern.split('.')\n",
        "          notes = []\n",
        "          for current_note in notes_in_chord:\n",
        "              new_note = note.Note(current_note)\n",
        "              notes.append(new_note)\n",
        "          new_chord = chord.Chord(notes)\n",
        "          new_chord.offset = offset\n",
        "          m1p.append(new_chord)\n",
        "      # note\n",
        "      else:\n",
        "          new_note = note.Note(pattern)\n",
        "          new_note.offset = offset\n",
        "          m1p.append(new_note)\n",
        "      # increase offset each iteration so that notes do not stack\n",
        "      offset += note_interval\n",
        "  p.append(m1p)\n",
        "  return p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8qAnJrqT5Pm"
      },
      "source": [
        "## Music Generation Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YGkYCQoiv3GZ"
      },
      "outputs": [],
      "source": [
        "# True or False\n",
        "Piano = True\n",
        "Drum = True\n",
        "Guitar = True\n",
        "Bass = True\n",
        "String = True\n",
        "Violin = False\n",
        "Saxophone = False\n",
        "\n",
        "# Value should be (0.2, 1.2)\n",
        "Piano_NoteInterval = 0.7\n",
        "Drum_NoteInterval = 0.7\n",
        "Guitar_NoteInterval = 0.7\n",
        "Bass_NoteInterval = 0.7\n",
        "String_NoteInterval = 0.7\n",
        "Violin_NoteInterval = 0.7\n",
        "Saxophone_NoteInterval = 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWlbIvpoUR-F"
      },
      "source": [
        "## Music Generaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R31ppDf01mS4"
      },
      "outputs": [],
      "source": [
        "transfer_dic = parser()\n",
        "midi_stream = stream.Score()\n",
        "\n",
        "# Add instrument according to parameters\n",
        "if Piano:\n",
        "  p = part_generate(instrument.Piano(), Piano_NoteInterval, transfer_dic)\n",
        "  midi_stream.insert(0, p)\n",
        "if Drum:\n",
        "  p = part_generate(instrument.BassDrum(), Drum_NoteInterval, transfer_dic)\n",
        "  midi_stream.insert(0, p)\n",
        "if Guitar:\n",
        "  p = part_generate(instrument.Guitar(), Guitar_NoteInterval, transfer_dic)\n",
        "  midi_stream.insert(0, p)\n",
        "if Bass:\n",
        "  p = part_generate(instrument.AcousticBass(), Bass_NoteInterval, transfer_dic)\n",
        "  midi_stream.insert(0, p)\n",
        "if String:\n",
        "  p = part_generate(instrument.StringInstrument(), String_NoteInterval, transfer_dic)\n",
        "  midi_stream.insert(0, p)\n",
        "if Violin:\n",
        "  p = part_generate(instrument.Violin(), Violin_NoteInterval, transfer_dic)\n",
        "  midi_stream.insert(0, p)\n",
        "if Saxophone:\n",
        "  p = part_generate(instrument.Saxophone(), Saxophone_NoteInterval, transfer_dic)\n",
        "  midi_stream.insert(0, p)\n",
        "\n",
        "# Create midi file\n",
        "midi_stream.write('midi', fp = 'gan_final.mid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XikkCyHLUiVy"
      },
      "source": [
        "## Create Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F0jN7MEr5GjZ"
      },
      "outputs": [],
      "source": [
        "!fluidsynth -ni font.sf2 gan_final.mid -F output.wav -r 44100\n",
        "sound_file = 'output.wav'\n",
        "Audio(sound_file)\n",
        "Audio(\"out1.wav\")\n",
        "Audio(\"out2.wav\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
